"""
å·å´å¸‚AEDæœ€é©é…ç½®åˆ†æ - ä¸€æ§˜åˆ†å¸ƒãƒ¢ãƒ‡ãƒ«
- å„ç”ºä¸ã®ãƒãƒªã‚´ãƒ³å†…ã«äººå£ãŒä¸€æ§˜ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã¨ä»®å®š
- ã‚°ãƒªãƒƒãƒ‰ç‚¹ã‚’ç”Ÿæˆã—ã¦ã‚«ãƒãƒ¼ç‡ã‚’è¨ˆç®—
"""

import shapefile
from shapely.geometry import shape, Point
import pandas as pd
import numpy as np
from math import radians, sin, cos, sqrt, atan2
import os

# ========================================
# è¨­å®š
# ========================================
ESTATS_DIR = '../estats'
AED_FILE = '../01_aed_data/kawasaki_aed_merged.csv'
POPULATION_DIR = '../kawasakishi_data'
GRID_SPACING = 50  # ã‚°ãƒªãƒƒãƒ‰é–“éš”ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰
COVER_DISTANCE = 300  # ã‚«ãƒãƒ¼ç¯„å›²ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰

# åŒºã‚³ãƒ¼ãƒ‰
# â€» e-Statã®ã‚·ã‚§ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯14135ã¨14136ã®ç”ºä¸ãŒå…¥ã‚Œæ›¿ã‚ã£ã¦ã„ã‚‹ãŸã‚
#    äººå£ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹ãŸã‚ã«åŒºåã‚’å…¥ã‚Œæ›¿ãˆ
WARD_CODES = {
    '14131': 'å·å´åŒº',
    '14132': 'å¹¸åŒº',
    '14133': 'ä¸­åŸåŒº',
    '14134': 'é«˜æ´¥åŒº',
    '14135': 'å¤šæ‘©åŒº',  # e-Statã§ã¯å®®å‰åŒºã‚³ãƒ¼ãƒ‰ã ãŒã€ç”ºä¸åã¯å¤šæ‘©åŒºã®ã‚‚ã®
    '14136': 'å®®å‰åŒº',  # e-Statã§ã¯å¤šæ‘©åŒºã‚³ãƒ¼ãƒ‰ã ãŒã€ç”ºä¸åã¯å®®å‰åŒºã®ã‚‚ã®
    '14137': 'éº»ç”ŸåŒº',
}

# å¹´é½¢åˆ¥ãƒªã‚¹ã‚¯é‡ã¿ï¼ˆæ±äº¬æ¶ˆé˜²åºã€Œä»¤å’Œ5å¹´ æ•‘æ€¥æ´»å‹•ã®ç¾æ³ã€ã«åŸºã¥ãï¼‰
# å‡ºå…¸: https://www.tfd.metro.tokyo.lg.jp/learning/elib/kyukyukatudojittai/r5.html
RISK_WEIGHTS = {
    '0ã€œ4æ­³': 0.71, '5ã€œ9æ­³': 0.16, '10ã€œ14æ­³': 0.18, '15ã€œ19æ­³': 0.51,
    '20ã€œ24æ­³': 0.76, '25ã€œ29æ­³': 0.43, '30ã€œ34æ­³': 0.69, '35ã€œ39æ­³': 0.57,
    '40ã€œ44æ­³': 1.00, '45ã€œ49æ­³': 1.12, '50ã€œ54æ­³': 2.33, '55ã€œ59æ­³': 2.59,
    '60ã€œ64æ­³': 4.00, '65ã€œ69æ­³': 4.35, '70ã€œ74æ­³': 6.73, '75ã€œ79æ­³': 11.63,
    '80ã€œ84æ­³': 19.45, '85ã€œ89æ­³': 30.78, '90ã€œ94æ­³': 50.02, '95ã€œ99æ­³': 72.24,
    '100æ­³ä»¥ä¸Š': 72.24
}

TARGET_YEARS = ['R7', 'R12', 'R17', 'R22', 'R27', 'R32', 'R37', 'R42', 'R47', 'R52']


def haversine_distance(lat1, lon1, lat2, lon2):
    """2ç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰"""
    R = 6371000  # åœ°çƒã®åŠå¾„ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    return R * 2 * atan2(sqrt(a), sqrt(1-a))


def meters_to_degrees(meters, latitude):
    """ãƒ¡ãƒ¼ãƒˆãƒ«ã‚’ç·¯åº¦çµŒåº¦ã®åº¦æ•°ã«å¤‰æ›ï¼ˆè¿‘ä¼¼ï¼‰"""
    # ç·¯åº¦1åº¦ â‰ˆ 111km
    lat_deg = meters / 111000
    # çµŒåº¦1åº¦ â‰ˆ 111km * cos(ç·¯åº¦)
    lon_deg = meters / (111000 * cos(radians(latitude)))
    return lat_deg, lon_deg


def generate_grid_points(polygon, spacing_m=50):
    """ãƒãƒªã‚´ãƒ³å†…ã«ã‚°ãƒªãƒƒãƒ‰ç‚¹ã‚’ç”Ÿæˆ"""
    minx, miny, maxx, maxy = polygon.bounds
    
    # ã‚°ãƒªãƒƒãƒ‰é–“éš”ã‚’åº¦æ•°ã«å¤‰æ›
    center_lat = (miny + maxy) / 2
    lat_spacing, lon_spacing = meters_to_degrees(spacing_m, center_lat)
    
    points = []
    y = miny
    while y <= maxy:
        x = minx
        while x <= maxx:
            p = Point(x, y)
            if polygon.contains(p):
                points.append((y, x))  # (ç·¯åº¦, çµŒåº¦)
            x += lon_spacing
        y += lat_spacing
    
    return points


def load_shapefiles():
    """å…¨åŒºã®Shapefileã‚’èª­ã¿è¾¼ã¿"""
    all_features = []
    
    for code, ward in WARD_CODES.items():
        shp_path = f'{ESTATS_DIR}/A002005212020DDSWC{code}/r2ka{code}.shp'
        
        if not os.path.exists(shp_path):
            print(f"  âš ï¸ {ward}ã®ShapefileãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            continue
        
        sf = shapefile.Reader(shp_path, encoding='shift_jis')
        
        for sr in sf.shapeRecords():
            rec = sr.record
            geom = shape(sr.shape.__geo_interface__)
            
            # S_NAMEãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            field_names = [f[0] for f in sf.fields[1:]]
            s_name_idx = field_names.index('S_NAME') if 'S_NAME' in field_names else None
            key_code_idx = field_names.index('KEY_CODE') if 'KEY_CODE' in field_names else None
            
            all_features.append({
                'ward': ward,
                'chocho_name': rec[s_name_idx] if s_name_idx else '',
                'key_code': rec[key_code_idx] if key_code_idx else '',
                'geometry': geom
            })
    
    return all_features


def load_population_data():
    """äººå£æ¨è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆå…¨å¹´æ¬¡åˆè¨ˆï¼‰"""
    all_data = []
    
    for year_code in TARGET_YEARS:
        file_path = f"{POPULATION_DIR}/ç”ºä¸åˆ¥å°†æ¥äººå£æ¨è¨ˆ({year_code}).csv"
        if os.path.exists(file_path):
            df = pd.read_csv(file_path, encoding='shift_jis')
            df['ãƒªã‚¹ã‚¯é‡ã¿'] = df['å¹´é½¢5æ­³éšç´š'].map(RISK_WEIGHTS)
            df['ãƒªã‚¹ã‚¯åŠ é‡äººå£'] = df['å°†æ¥æ¨è¨ˆäººå£'] * df['ãƒªã‚¹ã‚¯é‡ã¿']
            all_data.append(df)
    
    df_all = pd.concat(all_data, ignore_index=True)
    
    # ç”ºä¸ã”ã¨ã«åˆè¨ˆ
    pop_by_chocho = df_all.groupby(['è¡Œæ”¿åŒº', 'ç”ºä¸å']).agg({
        'å°†æ¥æ¨è¨ˆäººå£': 'sum',
        'ãƒªã‚¹ã‚¯åŠ é‡äººå£': 'sum'
    }).reset_index()
    
    pop_by_chocho.columns = ['åŒº', 'ç”ºä¸å', 'ç·äººå£_ç´¯è¨ˆ', 'ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ']
    
    return pop_by_chocho


def main():
    print("=" * 70)
    print("ğŸ—ºï¸  å·å´å¸‚AEDæœ€é©é…ç½®åˆ†æ - ä¸€æ§˜åˆ†å¸ƒãƒ¢ãƒ‡ãƒ«")
    print("=" * 70)
    print(f"ã‚°ãƒªãƒƒãƒ‰é–“éš”: {GRID_SPACING}m")
    print(f"ã‚«ãƒãƒ¼è·é›¢: {COVER_DISTANCE}m")
    
    # ========================================
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    # ========================================
    print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    # AEDãƒ‡ãƒ¼ã‚¿
    df_aed = pd.read_csv(AED_FILE)
    aed_locations = df_aed[['latitude', 'longitude']].dropna().values.tolist()
    print(f"  AEDæ•°: {len(aed_locations)}")
    
    # Shapefile
    print("  ç”ºä¸ãƒãƒªã‚´ãƒ³èª­ã¿è¾¼ã¿ä¸­...")
    features = load_shapefiles()
    print(f"  ç”ºä¸æ•°: {len(features)}")
    
    # äººå£ãƒ‡ãƒ¼ã‚¿
    print("  äººå£ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    pop_data = load_population_data()
    print(f"  äººå£ãƒ‡ãƒ¼ã‚¿: {len(pop_data)}ä»¶")
    
    # ========================================
    # å„ç”ºä¸ã®ã‚«ãƒãƒ¼ç‡è¨ˆç®—
    # ========================================
    print("\nğŸ“Š ã‚«ãƒãƒ¼ç‡è¨ˆç®—ä¸­...")
    print("  ï¼ˆã‚°ãƒªãƒƒãƒ‰ç‚¹ç”Ÿæˆ â†’ AEDè·é›¢è¨ˆç®— â†’ ã‚«ãƒãƒ¼ç‡ç®—å‡ºï¼‰")
    
    results = []
    total = len(features)
    
    for i, feat in enumerate(features):
        if (i + 1) % 50 == 0 or (i + 1) == total:
            print(f"  é€²æ—: {i+1}/{total} ({(i+1)/total*100:.0f}%)")
        
        polygon = feat['geometry']
        ward = feat['ward']
        chocho_name = feat['chocho_name']
        
        # ãƒãƒªã‚´ãƒ³ã®é‡å¿ƒåº§æ¨™ã‚’å–å¾—
        centroid = polygon.centroid
        centroid_lat = centroid.y
        centroid_lon = centroid.x
        
        # ã‚°ãƒªãƒƒãƒ‰ç‚¹ç”Ÿæˆ
        grid_points = generate_grid_points(polygon, GRID_SPACING)
        
        if len(grid_points) == 0:
            # ãƒãƒªã‚´ãƒ³ãŒå°ã•ã™ãã‚‹å ´åˆã¯ä¸­å¿ƒç‚¹ã‚’ä½¿ç”¨
            centroid = polygon.centroid
            grid_points = [(centroid.y, centroid.x)]
        
        # å„ã‚°ãƒªãƒƒãƒ‰ç‚¹ã®ã‚«ãƒãƒ¼çŠ¶æ³ã‚’åˆ¤å®š
        covered_count = 0
        min_distance = float('inf')
        
        for lat, lon in grid_points:
            # æœ€å¯„ã‚ŠAEDã¾ã§ã®è·é›¢
            for aed_lat, aed_lon in aed_locations:
                dist = haversine_distance(lat, lon, aed_lat, aed_lon)
                if dist < min_distance:
                    min_distance = dist
                if dist <= COVER_DISTANCE:
                    covered_count += 1
                    break  # ã“ã®ç‚¹ã¯ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹
        
        coverage_rate = covered_count / len(grid_points) if grid_points else 0
        
        # äººå£ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒƒãƒãƒ³ã‚°
        pop_row = pop_data[(pop_data['åŒº'] == ward) & (pop_data['ç”ºä¸å'] == chocho_name)]
        
        if not pop_row.empty:
            total_pop = pop_row['ç·äººå£_ç´¯è¨ˆ'].values[0]
            risk_pop = pop_row['ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ'].values[0]
        else:
            total_pop = 0
            risk_pop = 0
        
        covered_pop = total_pop * coverage_rate
        covered_risk_pop = risk_pop * coverage_rate
        
        results.append({
            'åŒº': ward,
            'ç”ºä¸å': chocho_name,
            'ç·¯åº¦': round(centroid_lat, 6),
            'çµŒåº¦': round(centroid_lon, 6),
            'ã‚°ãƒªãƒƒãƒ‰ç‚¹æ•°': len(grid_points),
            'ã‚«ãƒãƒ¼ç‡': round(coverage_rate * 100, 1),
            'ç·äººå£_ç´¯è¨ˆ': int(total_pop),
            'ã‚«ãƒãƒ¼äººå£_ç´¯è¨ˆ': int(covered_pop),
            'ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ': int(risk_pop),
            'ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ': int(covered_risk_pop),
            'æœ€å¯„ã‚ŠAEDè·é›¢_m': int(min_distance) if min_distance != float('inf') else None
        })
    
    # ========================================
    # çµæœé›†è¨ˆ
    # ========================================
    df_results = pd.DataFrame(results)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š åˆ†æçµæœ")
    print("=" * 70)
    
    total_pop = df_results['ç·äººå£_ç´¯è¨ˆ'].sum()
    covered_pop = df_results['ã‚«ãƒãƒ¼äººå£_ç´¯è¨ˆ'].sum()
    total_risk = df_results['ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ'].sum()
    covered_risk = df_results['ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ'].sum()
    
    print(f"\nã€ä¸€æ§˜åˆ†å¸ƒãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚«ãƒãƒ¼ç‡ã€‘")
    print(f"  ç·äººå£ï¼ˆç´¯è¨ˆï¼‰: {total_pop:,}")
    print(f"  ã‚«ãƒãƒ¼äººå£: {covered_pop:,} ({covered_pop/total_pop*100:.1f}%)")
    print(f"  ã‚«ãƒãƒ¼å¤–äººå£: {total_pop - covered_pop:,} ({(total_pop-covered_pop)/total_pop*100:.1f}%)")
    print(f"\n  ãƒªã‚¹ã‚¯åŠ é‡äººå£ï¼ˆç´¯è¨ˆï¼‰: {total_risk:,}")
    print(f"  ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£: {covered_risk:,} ({covered_risk/total_risk*100:.1f}%)")
    print(f"  ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£: {total_risk - covered_risk:,}")
    
    # ========================================
    # ã‚«ãƒãƒ¼ç‡ãŒä½ã„ç”ºä¸ï¼ˆå„ªå…ˆè¨­ç½®å€™è£œï¼‰
    # ========================================
    print("\n" + "=" * 70)
    print("ğŸ¯ AEDè¨­ç½®æ¨å¥¨åœ°åŸŸ TOP10ï¼ˆã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£é †ï¼‰")
    print("=" * 70)
    
    df_results['ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£'] = df_results['ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ'] - df_results['ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ']
    df_priority = df_results.sort_values('ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£', ascending=False)
    
    print("\nã€æ¨å¥¨å ´æ‰€ TOP10ã€‘")
    for rank, (_, row) in enumerate(df_priority.head(10).iterrows(), 1):
        print(f"\n{rank}ä½: {row['åŒº']} {row['ç”ºä¸å']}")
        print(f"   ã‚«ãƒãƒ¼ç‡: {row['ã‚«ãƒãƒ¼ç‡']}%")
        print(f"   ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£: {row['ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£']:,}")
        print(f"   æœ€å¯„ã‚ŠAED: {row['æœ€å¯„ã‚ŠAEDè·é›¢_m']}m")
    
    # ========================================
    # çµæœä¿å­˜
    # ========================================
    df_results.to_csv('uniform_model_results.csv', index=False, encoding='utf-8-sig')
    df_priority.head(20).to_csv('uniform_model_recommendations.csv', index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ’¾ çµæœä¿å­˜:")
    print(f"  - uniform_model_results.csv")
    print(f"  - uniform_model_recommendations.csv")
    
    print("\nâœ… åˆ†æå®Œäº†!")
    
    return df_results


if __name__ == '__main__':
    main()

