"""
ã‚°ãƒªãƒƒãƒ‰ãƒ¬ãƒ™ãƒ«ã§ã®AEDè¨­ç½®æ¨å¥¨å ´æ‰€åˆ†æ
å„ã‚°ãƒªãƒƒãƒ‰ç‚¹ã«AEDã‚’é…ç½®ã—ãŸå ´åˆã®ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼äººå£å¢—åŠ é‡ã‚’è¨ˆç®—
"""
import pandas as pd
import numpy as np
from math import radians, sin, cos, sqrt, atan2
import os
from shapely.geometry import shape
import shapefile

# ========================================
# è¨­å®š
# ========================================
GRID_SPACING = 50  # ã‚°ãƒªãƒƒãƒ‰é–“éš”ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰
COVER_DISTANCE = 300  # ã‚«ãƒãƒ¼ç¯„å›²ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰
AED_FILE = '../01_aed_data/kawasaki_aed_merged.csv'
ESTATS_DIR = '../estats'

# åŒºã‚³ãƒ¼ãƒ‰
WARD_CODES = {
    '14131': 'å·å´åŒº', '14132': 'å¹¸åŒº', '14133': 'ä¸­åŸåŒº',
    '14134': 'é«˜æ´¥åŒº', '14135': 'å¤šæ‘©åŒº', '14136': 'å®®å‰åŒº', '14137': 'éº»ç”ŸåŒº'
}

# ========================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ========================================
def haversine_distance(lat1, lon1, lat2, lon2):
    """2ç‚¹é–“ã®è·é›¢ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰"""
    R = 6371000
    phi1, phi2 = radians(lat1), radians(lat2)
    dphi = radians(lat2 - lat1)
    dlambda = radians(lon2 - lon1)
    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2
    return 2 * R * atan2(sqrt(a), sqrt(1-a))

def meters_to_degrees(meters, latitude):
    """ãƒ¡ãƒ¼ãƒˆãƒ«ã‚’åº¦ã«å¤‰æ›ï¼ˆè¿‘ä¼¼ï¼‰"""
    lat_deg = meters / 111320
    lon_deg = meters / (111320 * cos(radians(latitude)))
    return lat_deg, lon_deg

def generate_grid_points(polygon, spacing_m):
    """ãƒãƒªã‚´ãƒ³å†…ã«ã‚°ãƒªãƒƒãƒ‰ç‚¹ã‚’ç”Ÿæˆ"""
    bounds = polygon.bounds
    center_lat = (bounds[1] + bounds[3]) / 2
    lat_step, lon_step = meters_to_degrees(spacing_m, center_lat)
    
    points = []
    lat = bounds[1]
    while lat <= bounds[3]:
        lon = bounds[0]
        while lon <= bounds[2]:
            from shapely.geometry import Point
            if polygon.contains(Point(lon, lat)):
                points.append((lat, lon))
            lon += lon_step
        lat += lat_step
    return points

def load_shapefiles():
    """å…¨åŒºã®Shapefileã‚’èª­ã¿è¾¼ã¿"""
    all_features = []
    
    for code, ward in WARD_CODES.items():
        shp_path = f'{ESTATS_DIR}/A002005212020DDSWC{code}/r2ka{code}.shp'
        
        if not os.path.exists(shp_path):
            print(f"  âš ï¸ {ward}ã®ShapefileãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {shp_path}")
            continue
        
        sf = shapefile.Reader(shp_path, encoding='shift_jis')
        
        for sr in sf.shapeRecords():
            rec = sr.record
            geom = shape(sr.shape.__geo_interface__)
            
            # S_NAMEãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            field_names = [f[0] for f in sf.fields[1:]]
            s_name_idx = field_names.index('S_NAME') if 'S_NAME' in field_names else None
            
            if s_name_idx is not None:
                chocho_name = rec[s_name_idx]
                if chocho_name:
                    all_features.append({
                        'ward': ward,
                        'chocho_name': chocho_name,
                        'geometry': geom
                    })
    
    return all_features

def load_population_data():
    """äººå£ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    pop_file = 'chocho_analysis_all_years.csv'
    df = pd.read_csv(pop_file)
    # ã™ã§ã«ç´¯è¨ˆã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ç”ºä¸åã”ã¨ã«é›†ç´„ï¼ˆè¤‡æ•°ãƒãƒªã‚´ãƒ³å¯¾å¿œï¼‰
    df_agg = df.groupby(['åŒº', 'ç”ºä¸å']).agg({
        'ç·äººå£_ç´¯è¨ˆ': 'first',
        'ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ': 'first'
    }).reset_index()
    return df_agg

# ========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ========================================
def main():
    print("=" * 70)
    print("ğŸ¯ ã‚°ãƒªãƒƒãƒ‰ãƒ¬ãƒ™ãƒ«AEDè¨­ç½®æ¨å¥¨åˆ†æ")
    print("=" * 70)
    print(f"ã‚°ãƒªãƒƒãƒ‰é–“éš”: {GRID_SPACING}m")
    print(f"ã‚«ãƒãƒ¼è·é›¢: {COVER_DISTANCE}m")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    df_aed = pd.read_csv(AED_FILE)
    aed_locations = df_aed[['latitude', 'longitude']].dropna().values.tolist()
    print(f"  æ—¢å­˜AEDæ•°: {len(aed_locations)}")
    
    features = load_shapefiles()
    print(f"  ç”ºä¸ãƒãƒªã‚´ãƒ³æ•°: {len(features)}")
    
    pop_data = load_population_data()
    print(f"  äººå£ãƒ‡ãƒ¼ã‚¿: {len(pop_data)}ä»¶")
    
    # ========================================
    # å…¨ã‚°ãƒªãƒƒãƒ‰ç‚¹ã‚’ç”Ÿæˆã—ã€ç¾åœ¨ã®ã‚«ãƒãƒ¼çŠ¶æ³ã‚’è¨ˆç®—
    # ========================================
    print("\nğŸ“Š å…¨ã‚°ãƒªãƒƒãƒ‰ç‚¹ã®ã‚«ãƒãƒ¼çŠ¶æ³ã‚’åˆ†æä¸­...")
    
    all_grid_points = []  # (lat, lon, ward, chocho, risk_weight_per_point)
    
    for i, feat in enumerate(features):
        if (i + 1) % 100 == 0:
            print(f"  é€²æ—: {i+1}/{len(features)}")
        
        polygon = feat['geometry']
        ward = feat['ward']
        chocho_name = feat['chocho_name']
        
        grid_points = generate_grid_points(polygon, GRID_SPACING)
        if len(grid_points) == 0:
            centroid = polygon.centroid
            grid_points = [(centroid.y, centroid.x)]
        
        # äººå£ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒƒãƒãƒ³ã‚°
        pop_row = pop_data[(pop_data['åŒº'] == ward) & (pop_data['ç”ºä¸å'] == chocho_name)]
        if not pop_row.empty:
            risk_pop = pop_row['ãƒªã‚¹ã‚¯åŠ é‡äººå£_ç´¯è¨ˆ'].values[0]
        else:
            risk_pop = 0
        
        # å„ã‚°ãƒªãƒƒãƒ‰ç‚¹ã®ãƒªã‚¹ã‚¯åŠ é‡äººå£ï¼ˆå‡ç­‰é…åˆ†ï¼‰
        risk_per_point = risk_pop / len(grid_points) if grid_points else 0
        
        for lat, lon in grid_points:
            # ç¾åœ¨ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã‹åˆ¤å®š
            is_covered = False
            for aed_lat, aed_lon in aed_locations:
                if haversine_distance(lat, lon, aed_lat, aed_lon) <= COVER_DISTANCE:
                    is_covered = True
                    break
            
            all_grid_points.append({
                'lat': lat,
                'lon': lon,
                'ward': ward,
                'chocho': chocho_name,
                'risk_weight': risk_per_point,
                'is_covered': is_covered
            })
    
    df_grid = pd.DataFrame(all_grid_points)
    
    total_points = len(df_grid)
    covered_points = df_grid['is_covered'].sum()
    uncovered_points = total_points - covered_points
    
    print(f"\n  å…¨ã‚°ãƒªãƒƒãƒ‰ç‚¹æ•°: {total_points:,}")
    print(f"  ã‚«ãƒãƒ¼æ¸ˆã¿: {covered_points:,} ({covered_points/total_points*100:.1f}%)")
    print(f"  æœªã‚«ãƒãƒ¼: {uncovered_points:,} ({uncovered_points/total_points*100:.1f}%)")
    
    # ã‚«ãƒãƒ¼å¤–ã®ã‚°ãƒªãƒƒãƒ‰ç‚¹ã®ã¿æŠ½å‡º
    df_uncovered = df_grid[~df_grid['is_covered']].copy()
    
    print(f"\n  æœªã‚«ãƒãƒ¼ã®ãƒªã‚¹ã‚¯åŠ é‡äººå£åˆè¨ˆ: {df_uncovered['risk_weight'].sum():,.0f}")
    
    # ========================================
    # å„å€™è£œåœ°ç‚¹ï¼ˆæœªã‚«ãƒãƒ¼ã‚°ãƒªãƒƒãƒ‰ç‚¹ï¼‰ã®åŠ¹æœã‚’è¨ˆç®—
    # ========================================
    print("\nğŸ” å„å€™è£œåœ°ç‚¹ã®åŠ¹æœã‚’è¨ˆç®—ä¸­...")
    print("  ï¼ˆå„ã‚°ãƒªãƒƒãƒ‰ç‚¹ã«AEDã‚’ç½®ã„ãŸå ´åˆã®æ–°è¦ã‚«ãƒãƒ¼äººå£ã‚’è¨ˆç®—ï¼‰")
    
    # æœªã‚«ãƒãƒ¼ç‚¹ã®åº§æ¨™ã‚’numpyé…åˆ—ã«å¤‰æ›ï¼ˆé«˜é€ŸåŒ–ï¼‰
    uncovered_coords = df_uncovered[['lat', 'lon']].values
    uncovered_risks = df_uncovered['risk_weight'].values
    
    # å€™è£œåœ°ç‚¹ã¯æœªã‚«ãƒãƒ¼ç‚¹ã«é™å®š
    candidates = df_uncovered[['lat', 'lon', 'ward', 'chocho']].drop_duplicates().values
    print(f"  å€™è£œåœ°ç‚¹æ•°: {len(candidates):,}")
    
    results = []
    total_candidates = len(candidates)
    
    for idx, (c_lat, c_lon, c_ward, c_chocho) in enumerate(candidates):
        if (idx + 1) % 1000 == 0:
            print(f"  é€²æ—: {idx+1}/{total_candidates} ({(idx+1)/total_candidates*100:.1f}%)")
        
        # ã“ã®å€™è£œåœ°ç‚¹ã«AEDã‚’ç½®ã„ãŸå ´åˆã€æ–°ãŸã«ã‚«ãƒãƒ¼ã•ã‚Œã‚‹ç‚¹ã‚’è¨ˆç®—
        new_covered_risk = 0
        for i, (u_lat, u_lon) in enumerate(uncovered_coords):
            dist = haversine_distance(c_lat, c_lon, u_lat, u_lon)
            if dist <= COVER_DISTANCE:
                new_covered_risk += uncovered_risks[i]
        
        results.append({
            'ç·¯åº¦': round(c_lat, 6),
            'çµŒåº¦': round(c_lon, 6),
            'åŒº': c_ward,
            'ç”ºä¸å': c_chocho,
            'æ–°è¦ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£': int(new_covered_risk)
        })
    
    df_results = pd.DataFrame(results)
    df_results = df_results.sort_values('æ–°è¦ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£', ascending=False)
    
    # ========================================
    # çµæœè¡¨ç¤º
    # ========================================
    print("\n" + "=" * 70)
    print("ğŸ† AEDè¨­ç½®æ¨å¥¨åœ°ç‚¹ TOP20ï¼ˆã‚°ãƒªãƒƒãƒ‰ãƒ¬ãƒ™ãƒ«ï¼‰")
    print("=" * 70)
    print("â€» 1å°è¨­ç½®ã—ãŸå ´åˆã«æ–°ãŸã«ã‚«ãƒãƒ¼ã•ã‚Œã‚‹ãƒªã‚¹ã‚¯åŠ é‡äººå£")
    
    for rank, (_, row) in enumerate(df_results.head(20).iterrows(), 1):
        print(f"\n{rank}ä½: {row['åŒº']} {row['ç”ºä¸å']}")
        print(f"   åº§æ¨™: ({row['ç·¯åº¦']}, {row['çµŒåº¦']})")
        print(f"   æ–°è¦ã‚«ãƒãƒ¼: {row['æ–°è¦ã‚«ãƒãƒ¼ãƒªã‚¹ã‚¯åŠ é‡äººå£']:,}")
    
    # ä¿å­˜
    df_results.head(100).to_csv('grid_level_recommendations.csv', index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ çµæœä¿å­˜: grid_level_recommendations.csv (TOP100)")
    
    print("\nâœ… åˆ†æå®Œäº†!")
    
    return df_results

if __name__ == '__main__':
    main()
