"""
å·å´å¸‚AEDæœ€é©é…ç½®åˆ†æ - å°†æ¥äººå£æ¨è¨ˆã‚’åŠ å‘³ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³
- 2025å¹´ã€œ2070å¹´ã®äººå£æ¨è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
- ãƒªã‚¹ã‚¯åŠ é‡äººå£ã®å°†æ¥æ¨ç§»ã‚’åˆ†æ
- é•·æœŸçš„ã«æœ€é©ãªAEDé…ç½®ã‚’ææ¡ˆ
"""

import pandas as pd
import numpy as np
from math import radians, sin, cos, sqrt, atan2
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
plt.rcParams['font.family'] = 'Hiragino Sans'

# ========================================
# è¨­å®š
# ========================================
DATA_DIR = '../kawasakishi_data'
AED_FILE = '../01_aed_data/kawasaki_aed_merged.csv'

# å¹´é½¢åˆ¥ãƒªã‚¹ã‚¯é‡ã¿ï¼ˆæ±äº¬æ¶ˆé˜²åºã€Œä»¤å’Œ5å¹´ æ•‘æ€¥æ´»å‹•ã®ç¾æ³ã€ã«åŸºã¥ãï¼‰
# å‡ºå…¸: https://www.tfd.metro.tokyo.lg.jp/learning/elib/kyukyukatudojittai/r5.html
RISK_WEIGHTS = {
    '0ã€œ4æ­³': 0.71, '5ã€œ9æ­³': 0.16, '10ã€œ14æ­³': 0.18, '15ã€œ19æ­³': 0.51,
    '20ã€œ24æ­³': 0.76, '25ã€œ29æ­³': 0.43, '30ã€œ34æ­³': 0.69, '35ã€œ39æ­³': 0.57,
    '40ã€œ44æ­³': 1.00, '45ã€œ49æ­³': 1.12, '50ã€œ54æ­³': 2.33, '55ã€œ59æ­³': 2.59,
    '60ã€œ64æ­³': 4.00, '65ã€œ69æ­³': 4.35, '70ã€œ74æ­³': 6.73, '75ã€œ79æ­³': 11.63,
    '80ã€œ84æ­³': 19.45, '85ã€œ89æ­³': 30.78, '90ã€œ94æ­³': 50.02, '95ã€œ99æ­³': 72.24,
    '100æ­³ä»¥ä¸Š': 35.56
}

# åˆ†æå¯¾è±¡å¹´
TARGET_YEARS = {
    'R7': 2025, 'R12': 2030, 'R17': 2035, 'R22': 2040, 'R27': 2045,
    'R32': 2050, 'R37': 2055, 'R42': 2060, 'R47': 2065, 'R52': 2070
}


def haversine_distance(lat1, lon1, lat2, lon2):
    """2ç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—ï¼ˆkmï¼‰"""
    R = 6371
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    return R * 2 * atan2(sqrt(a), sqrt(1-a))


def load_population_data(year_code):
    """æŒ‡å®šå¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    file_path = f"{DATA_DIR}/ç”ºä¸åˆ¥å°†æ¥äººå£æ¨è¨ˆ({year_code}).csv"
    df = pd.read_csv(file_path, encoding='shift_jis')
    return df


def calculate_risk_weighted_population(df):
    """ãƒªã‚¹ã‚¯åŠ é‡äººå£ã‚’è¨ˆç®—"""
    df = df.copy()
    df['ãƒªã‚¹ã‚¯é‡ã¿'] = df['å¹´é½¢5æ­³éšç´š'].map(RISK_WEIGHTS)
    df['ãƒªã‚¹ã‚¯åŠ é‡äººå£'] = df['å°†æ¥æ¨è¨ˆäººå£'] * df['ãƒªã‚¹ã‚¯é‡ã¿']
    return df


def analyze_by_chocho(df, df_aed):
    """ç”ºä¸ã”ã¨ã®åˆ†æ"""
    # ç”ºä¸ã”ã¨ã«é›†è¨ˆï¼ˆç”·å¥³åˆè¨ˆï¼‰
    chocho = df.groupby(['ç”ºä¸ã‚³ãƒ¼ãƒ‰', 'è¡Œæ”¿åŒº', 'ç”ºä¸å', 'X_CODE', 'Y_CODE']).agg({
        'å°†æ¥æ¨è¨ˆäººå£': 'sum',
        'ãƒªã‚¹ã‚¯åŠ é‡äººå£': 'sum'
    }).reset_index()
    
    chocho.columns = ['ç”ºä¸ã‚³ãƒ¼ãƒ‰', 'åŒº', 'ç”ºä¸å', 'çµŒåº¦', 'ç·¯åº¦', 'ç·äººå£', 'ãƒªã‚¹ã‚¯åŠ é‡äººå£']
    
    # å„ç”ºä¸ã®æœ€å¯„ã‚ŠAEDã¾ã§ã®è·é›¢ã¨500mä»¥å†…AEDæ•°ã‚’è¨ˆç®—
    distances = []
    aed_counts = []
    
    for _, row in chocho.iterrows():
        if pd.isna(row['ç·¯åº¦']) or pd.isna(row['çµŒåº¦']):
            distances.append(np.nan)
            aed_counts.append(0)
            continue
        
        min_dist = float('inf')
        count_500m = 0
        
        for _, aed in df_aed.iterrows():
            if pd.isna(aed['latitude']) or pd.isna(aed['longitude']):
                continue
            
            dist = haversine_distance(row['ç·¯åº¦'], row['çµŒåº¦'], aed['latitude'], aed['longitude'])
            if dist < min_dist:
                min_dist = dist
            if dist <= 0.5:
                count_500m += 1
        
        distances.append(min_dist if min_dist != float('inf') else np.nan)
        aed_counts.append(count_500m)
    
    chocho['æœ€å¯„ã‚ŠAEDè·é›¢_km'] = distances
    chocho['500mä»¥å†…AEDæ•°'] = aed_counts
    
    return chocho


def main():
    print("=" * 70)
    print("ğŸ”® å·å´å¸‚AEDæœ€é©é…ç½®åˆ†æ - å°†æ¥äººå£æ¨è¨ˆç‰ˆ")
    print("=" * 70)
    
    # AEDãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“‚ AEDãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    df_aed = pd.read_csv(AED_FILE)
    print(f"  AEDæ•°: {len(df_aed)}")
    
    # å„å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ
    results = []
    
    for year_code, year in sorted(TARGET_YEARS.items(), key=lambda x: x[1]):
        print(f"\nğŸ“… {year}å¹´ï¼ˆ{year_code}ï¼‰ã‚’åˆ†æä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = load_population_data(year_code)
        df = calculate_risk_weighted_population(df)
        
        # ç”ºä¸ã”ã¨ã®åˆ†æ
        chocho = analyze_by_chocho(df, df_aed)
        
        # çµ±è¨ˆè¨ˆç®—
        total_pop = chocho['ç·äººå£'].sum()
        total_risk_pop = chocho['ãƒªã‚¹ã‚¯åŠ é‡äººå£'].sum()
        
        covered = chocho[chocho['500mä»¥å†…AEDæ•°'] > 0]
        covered_pop = covered['ç·äººå£'].sum()
        covered_risk_pop = covered['ãƒªã‚¹ã‚¯åŠ é‡äººå£'].sum()
        
        coverage_rate = covered_pop / total_pop * 100
        risk_coverage_rate = covered_risk_pop / total_risk_pop * 100
        
        # é«˜é½¢è€…äººå£ï¼ˆ65æ­³ä»¥ä¸Šï¼‰
        elderly_ages = ['65ã€œ69æ­³', '70ã€œ74æ­³', '75ã€œ79æ­³', '80ã€œ84æ­³', '85ã€œ89æ­³', '90ã€œ94æ­³', '95ã€œ99æ­³', '100æ­³ä»¥ä¸Š']
        df_elderly = df[df['å¹´é½¢5æ­³éšç´š'].isin(elderly_ages)]
        elderly_pop = df_elderly['å°†æ¥æ¨è¨ˆäººå£'].sum()
        elderly_rate = elderly_pop / total_pop * 100
        
        results.append({
            'å¹´': year,
            'ç·äººå£': int(total_pop),
            'é«˜é½¢è€…äººå£': int(elderly_pop),
            'é«˜é½¢åŒ–ç‡': round(elderly_rate, 1),
            'ãƒªã‚¹ã‚¯åŠ é‡äººå£': int(total_risk_pop),
            'ã‚«ãƒãƒ¼ç‡': round(coverage_rate, 1),
            'ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡': round(risk_coverage_rate, 1),
            'ã‚«ãƒãƒ¼å¤–äººå£': int(total_pop - covered_pop),
            'ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£': int(total_risk_pop - covered_risk_pop)
        })
        
        print(f"  ç·äººå£: {total_pop:,}äºº")
        print(f"  é«˜é½¢åŒ–ç‡: {elderly_rate:.1f}%")
        print(f"  ã‚«ãƒãƒ¼ç‡: {coverage_rate:.1f}%")
        print(f"  ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡: {risk_coverage_rate:.1f}%")
        
        # 2025å¹´ã¨2045å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        if year in [2025, 2045]:
            chocho.to_csv(f'chocho_analysis_{year}.csv', index=False, encoding='utf-8-sig')
    
    # çµæœã‚’DataFrameã«
    df_results = pd.DataFrame(results)
    df_results.to_csv('future_population_analysis.csv', index=False, encoding='utf-8-sig')
    
    # ========================================
    # å°†æ¥äºˆæ¸¬ã‚’åŠ å‘³ã—ãŸAEDé…ç½®å„ªå…ˆåº¦
    # ========================================
    print("\n" + "=" * 70)
    print("ğŸ¯ å°†æ¥ã‚’è¦‹æ®ãˆãŸAEDé…ç½®å„ªå…ˆåº¦åˆ†æ")
    print("=" * 70)
    
    # 2025å¹´ã¨2045å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒ
    df_2025 = load_population_data('R7')
    df_2025 = calculate_risk_weighted_population(df_2025)
    chocho_2025 = analyze_by_chocho(df_2025, df_aed)
    
    df_2045 = load_population_data('R27')
    df_2045 = calculate_risk_weighted_population(df_2045)
    chocho_2045 = analyze_by_chocho(df_2045, df_aed)
    
    # ãƒãƒ¼ã‚¸ã—ã¦ãƒªã‚¹ã‚¯åŠ é‡äººå£ã®å¤‰åŒ–ã‚’è¨ˆç®—
    merged = chocho_2025[['ç”ºä¸ã‚³ãƒ¼ãƒ‰', 'åŒº', 'ç”ºä¸å', 'çµŒåº¦', 'ç·¯åº¦', 'ç·äººå£', 'ãƒªã‚¹ã‚¯åŠ é‡äººå£', 'æœ€å¯„ã‚ŠAEDè·é›¢_km', '500mä»¥å†…AEDæ•°']].copy()
    merged.columns = ['ç”ºä¸ã‚³ãƒ¼ãƒ‰', 'åŒº', 'ç”ºä¸å', 'çµŒåº¦', 'ç·¯åº¦', 'äººå£_2025', 'ãƒªã‚¹ã‚¯åŠ é‡_2025', 'æœ€å¯„ã‚ŠAEDè·é›¢_km', '500mä»¥å†…AEDæ•°']
    
    merged = merged.merge(
        chocho_2045[['ç”ºä¸ã‚³ãƒ¼ãƒ‰', 'ç·äººå£', 'ãƒªã‚¹ã‚¯åŠ é‡äººå£']].rename(
            columns={'ç·äººå£': 'äººå£_2045', 'ãƒªã‚¹ã‚¯åŠ é‡äººå£': 'ãƒªã‚¹ã‚¯åŠ é‡_2045'}
        ),
        on='ç”ºä¸ã‚³ãƒ¼ãƒ‰', how='left'
    )
    
    merged['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–'] = merged['ãƒªã‚¹ã‚¯åŠ é‡_2045'] - merged['ãƒªã‚¹ã‚¯åŠ é‡_2025']
    merged['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–ç‡'] = (merged['ãƒªã‚¹ã‚¯åŠ é‡_2045'] / merged['ãƒªã‚¹ã‚¯åŠ é‡_2025'] - 1) * 100
    
    # ç©ºç™½åœ°å¸¯ã®ã¿
    blank = merged[merged['500mä»¥å†…AEDæ•°'] == 0].copy()
    
    # å°†æ¥é‡è¦–ã®å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢
    # = 2045å¹´ãƒªã‚¹ã‚¯åŠ é‡äººå£ Ã— 0.5 + 2025å¹´ãƒªã‚¹ã‚¯åŠ é‡äººå£ Ã— 0.3 + ãƒªã‚¹ã‚¯åŠ é‡å¢—åŠ åˆ† Ã— 0.2
    blank['å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢'] = (
        blank['ãƒªã‚¹ã‚¯åŠ é‡_2045'] * 0.5 +
        blank['ãƒªã‚¹ã‚¯åŠ é‡_2025'] * 0.3 +
        blank['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–'].clip(lower=0) * 0.2  # å¢—åŠ åˆ†ã®ã¿è€ƒæ…®
    )
    
    # æ­£è¦åŒ–
    max_score = blank['å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢'].max()
    blank['å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢_æ­£è¦åŒ–'] = blank['å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢'] / max_score * 100
    
    # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆ
    priority = blank.sort_values('å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢_æ­£è¦åŒ–', ascending=False)
    
    print("\nã€å°†æ¥ã‚’è¦‹æ®ãˆãŸAEDè¨­ç½®æ¨å¥¨å ´æ‰€ TOP10ã€‘")
    print("-" * 70)
    
    recommendations = []
    for rank, (_, row) in enumerate(priority.head(10).iterrows(), 1):
        change_str = f"+{row['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–ç‡']:.0f}%" if row['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–ç‡'] > 0 else f"{row['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–ç‡']:.0f}%"
        print(f"\n{rank}ä½: {row['åŒº']} {row['ç”ºä¸å']}")
        print(f"   å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢: {row['å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢_æ­£è¦åŒ–']:.1f}")
        print(f"   2025å¹´ãƒªã‚¹ã‚¯åŠ é‡äººå£: {row['ãƒªã‚¹ã‚¯åŠ é‡_2025']:,.0f}")
        print(f"   2045å¹´ãƒªã‚¹ã‚¯åŠ é‡äººå£: {row['ãƒªã‚¹ã‚¯åŠ é‡_2045']:,.0f} ({change_str})")
        print(f"   æœ€å¯„ã‚ŠAED: {row['æœ€å¯„ã‚ŠAEDè·é›¢_km']:.2f}km")
        
        recommendations.append({
            'é †ä½': rank,
            'åŒº': row['åŒº'],
            'ç”ºä¸å': row['ç”ºä¸å'],
            'å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢': round(row['å°†æ¥é‡è¦–ã‚¹ã‚³ã‚¢_æ­£è¦åŒ–'], 1),
            'äººå£_2025': int(row['äººå£_2025']),
            'äººå£_2045': int(row['äººå£_2045']),
            'ãƒªã‚¹ã‚¯åŠ é‡_2025': int(row['ãƒªã‚¹ã‚¯åŠ é‡_2025']),
            'ãƒªã‚¹ã‚¯åŠ é‡_2045': int(row['ãƒªã‚¹ã‚¯åŠ é‡_2045']),
            'ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–ç‡': round(row['ãƒªã‚¹ã‚¯åŠ é‡å¤‰åŒ–ç‡'], 1),
            'æœ€å¯„ã‚ŠAEDè·é›¢_km': round(row['æœ€å¯„ã‚ŠAEDè·é›¢_km'], 2),
            'ç·¯åº¦': row['ç·¯åº¦'],
            'çµŒåº¦': row['çµŒåº¦']
        })
    
    df_rec = pd.DataFrame(recommendations)
    df_rec.to_csv('future_aed_recommendations.csv', index=False, encoding='utf-8-sig')
    
    # ========================================
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    # ========================================
    print("\nğŸ“Š ã‚°ãƒ©ãƒ•ä½œæˆä¸­...")
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. ç·äººå£ã¨é«˜é½¢åŒ–ç‡ã®æ¨ç§»
    ax1 = axes[0, 0]
    ax1_twin = ax1.twinx()
    years = df_results['å¹´']
    ax1.bar(years, df_results['ç·äººå£']/10000, color='steelblue', alpha=0.7, label='ç·äººå£')
    ax1_twin.plot(years, df_results['é«˜é½¢åŒ–ç‡'], 'ro-', linewidth=2, markersize=8, label='é«˜é½¢åŒ–ç‡')
    ax1.set_xlabel('å¹´')
    ax1.set_ylabel('ç·äººå£ï¼ˆä¸‡äººï¼‰', color='steelblue')
    ax1_twin.set_ylabel('é«˜é½¢åŒ–ç‡ï¼ˆ%ï¼‰', color='red')
    ax1.set_title('å·å´å¸‚ã®äººå£ã¨é«˜é½¢åŒ–ç‡ã®æ¨ç§»')
    ax1.legend(loc='upper left')
    ax1_twin.legend(loc='upper right')
    
    # 2. ãƒªã‚¹ã‚¯åŠ é‡äººå£ã®æ¨ç§»
    ax2 = axes[0, 1]
    ax2.plot(years, df_results['ãƒªã‚¹ã‚¯åŠ é‡äººå£']/10000, 'g^-', linewidth=2, markersize=8)
    ax2.set_xlabel('å¹´')
    ax2.set_ylabel('ãƒªã‚¹ã‚¯åŠ é‡äººå£ï¼ˆä¸‡äººï¼‰')
    ax2.set_title('å¿ƒåœæ­¢ãƒªã‚¹ã‚¯åŠ é‡äººå£ã®æ¨ç§»')
    ax2.grid(True, alpha=0.3)
    
    # 3. ã‚«ãƒãƒ¼ç‡ã®æ¨ç§»ï¼ˆç¾çŠ¶AEDç¶­æŒã®å ´åˆï¼‰
    ax3 = axes[1, 0]
    ax3.plot(years, df_results['ã‚«ãƒãƒ¼ç‡'], 'b-', linewidth=2, marker='o', label='ã‚·ãƒ³ãƒ—ãƒ«ã‚«ãƒãƒ¼ç‡')
    ax3.plot(years, df_results['ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡'], 'r--', linewidth=2, marker='s', label='ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡')
    ax3.set_xlabel('å¹´')
    ax3.set_ylabel('ã‚«ãƒãƒ¼ç‡ï¼ˆ%ï¼‰')
    ax3.set_title('AEDã‚«ãƒãƒ¼ç‡ã®æ¨ç§»ï¼ˆç¾çŠ¶ç¶­æŒã®å ´åˆï¼‰')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim(90, 100)
    
    # 4. ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£ã®æ¨ç§»
    ax4 = axes[1, 1]
    ax4.bar(years, df_results['ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£']/1000, color='coral', alpha=0.8)
    ax4.set_xlabel('å¹´')
    ax4.set_ylabel('ã‚«ãƒãƒ¼å¤–ãƒªã‚¹ã‚¯åŠ é‡äººå£ï¼ˆåƒäººï¼‰')
    ax4.set_title('AEDç©ºç™½åœ°å¸¯ã®ãƒªã‚¹ã‚¯åŠ é‡äººå£')
    ax4.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig('future_analysis_charts.png', dpi=150, bbox_inches='tight')
    print("ğŸ’¾ ã‚°ãƒ©ãƒ•ä¿å­˜: future_analysis_charts.png")
    
    # ========================================
    # ã‚µãƒãƒªãƒ¼
    # ========================================
    print("\n" + "=" * 70)
    print("ğŸ“‹ åˆ†æã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    
    r_2025 = df_results[df_results['å¹´'] == 2025].iloc[0]
    r_2045 = df_results[df_results['å¹´'] == 2045].iloc[0]
    r_2070 = df_results[df_results['å¹´'] == 2070].iloc[0]
    
    print(f"\nã€äººå£æ¨ç§»ã€‘")
    print(f"  2025å¹´: {r_2025['ç·äººå£']:,}äººï¼ˆé«˜é½¢åŒ–ç‡ {r_2025['é«˜é½¢åŒ–ç‡']}%ï¼‰")
    print(f"  2045å¹´: {r_2045['ç·äººå£']:,}äººï¼ˆé«˜é½¢åŒ–ç‡ {r_2045['é«˜é½¢åŒ–ç‡']}%ï¼‰")
    print(f"  2070å¹´: {r_2070['ç·äººå£']:,}äººï¼ˆé«˜é½¢åŒ–ç‡ {r_2070['é«˜é½¢åŒ–ç‡']}%ï¼‰")
    
    print(f"\nã€ãƒªã‚¹ã‚¯åŠ é‡äººå£ã®å¤‰åŒ–ã€‘")
    print(f"  2025å¹´: {r_2025['ãƒªã‚¹ã‚¯åŠ é‡äººå£']:,}")
    print(f"  2045å¹´: {r_2045['ãƒªã‚¹ã‚¯åŠ é‡äººå£']:,} ({(r_2045['ãƒªã‚¹ã‚¯åŠ é‡äººå£']/r_2025['ãƒªã‚¹ã‚¯åŠ é‡äººå£']-1)*100:+.1f}%)")
    print(f"  2070å¹´: {r_2070['ãƒªã‚¹ã‚¯åŠ é‡äººå£']:,} ({(r_2070['ãƒªã‚¹ã‚¯åŠ é‡äººå£']/r_2025['ãƒªã‚¹ã‚¯åŠ é‡äººå£']-1)*100:+.1f}%)")
    
    print(f"\nã€ç¾çŠ¶AEDç¶­æŒæ™‚ã®ã‚«ãƒãƒ¼ç‡å¤‰åŒ–ã€‘")
    print(f"  2025å¹´: {r_2025['ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡']}%")
    print(f"  2045å¹´: {r_2045['ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡']}%")
    print(f"  2070å¹´: {r_2070['ãƒªã‚¹ã‚¯åŠ é‡ã‚«ãƒãƒ¼ç‡']}%")
    
    print("\nğŸ’¾ çµæœä¿å­˜:")
    print("  - future_population_analysis.csv")
    print("  - future_aed_recommendations.csv")
    print("  - chocho_analysis_2025.csv")
    print("  - chocho_analysis_2045.csv")
    print("  - future_analysis_charts.png")
    
    print("\nâœ… åˆ†æå®Œäº†!")


if __name__ == '__main__':
    main()


